{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/ifajcik/efficientqa_pruned/efficientQA_submission'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "os.chdir(\"../\")\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " configurations\n",
      " Dockerfile\n",
      " download_data.sh\n",
      " efficientqa_eval\n",
      " efficientqa_input\n",
      " efficientqa_output\n",
      " fit_qa\n",
      " fusion\n",
      " language\n",
      " NQ-open.efficientqa.dev.1.1.no-annotations.jsonl_abstractive_reader_outputs.json\n",
      " NQ-open.efficientqa.dev.1.1.no-annotations.jsonl_fused.json\n",
      " NQ-open.efficientqa.dev.1.1.no-annotations.jsonlfused_w_abs.json\n",
      " NQ-open.efficientqa.dev.1.1.no-annotations.jsonl_fused_with_r_rr.json\n",
      " NQ-open.efficientqa.dev.1.1.no-annotations.jsonl_gen_reranked_reader_outputs.json\n",
      "'NQ-open.efficientqa.dev.1.1.no-annotations.jsonl_preprocessed_queryenc_wikipassages_NQ_open_val_<class '\\''transformers.tokenization_roberta.RobertaTokenizer'\\''>.json'\n",
      " NQ-open.efficientqa.dev.1.1.no-annotations.jsonl_ranked_outputs.jsonl\n",
      " NQ-open.efficientqa.dev.1.1.no-annotations.jsonl_reader_outputs.json\n",
      " NQ-open.efficientqa.dev.1.1.no-annotations.jsonl_reranked_outputs.jsonl\n",
      " NQ-open.efficientqa.dev.1.1.no-annotations.jsonl_reranked_outputs.jsonl_fuseindecoder_preprocessed_for_C25_t5-base_L512.json\n",
      " README.md\n",
      " requirements.txt\n",
      " run_prediction_efficientqa.py\n",
      " submission.sh\n",
      " test_docker_image.sh\n",
      " test_nodocker.sh\n"
     ]
    }
   ],
   "source": [
    "!ls "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "fused_dataf = \"NQ-open.efficientqa.dev.1.1.no-annotations.jsonl_fused_with_r_rr.json\"\n",
    "abstractive_data = \"NQ-open.efficientqa.dev.1.1.no-annotations.jsonl_abstractive_reader_outputs.json\"\n",
    "gt_file = \"efficientqa_eval/NQ-open.efficientqa.dev.1.1.jsonl\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import jsonlines\n",
    "\n",
    "with open(fused_dataf) as f:\n",
    "    er = json.load(f)\n",
    "with open(abstractive_data) as f:\n",
    "    gr = json.load(f)\n",
    "correct = {x['question']:x['answer'] for x in list(jsonlines.open(gt_file))}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def argmax(l):\n",
    "    f = lambda i: l[i]\n",
    "    return max(range(len(l)), key=f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy 47.66667, (858/1800)\n",
      "Accuracy 43.50000, (783/1800)\n"
     ]
    }
   ],
   "source": [
    "import fit_qa.scripts.common.evaluate_predictions as eval_utils\n",
    "from fit_qa.scripts.common.evaluate_predictions import exact_match_score\n",
    "\n",
    "def evaluate(preds, gts):\n",
    "    assert len(preds) == len(gts)\n",
    "    hits = 0\n",
    "    for q, a in preds.items():\n",
    "        gt_answers = gts[q]\n",
    "        hits+= int(eval_utils.metric_max_over_ground_truths(\n",
    "            metric_fn=exact_match_score, prediction=a, ground_truths=gt_answers))\n",
    "    print(f\"Accuracy {hits*100./len(preds):.5f}, ({hits}/{len(preds)})\")\n",
    "    \n",
    "e_predictions = {e['raw_question'] :e['answers'][argmax(e['reader_scores'])]   for e in er.values()}\n",
    "a_predictions = {e['raw_question'] :e['answers'][argmax(e['reader_scores'])]   for e in gr.values()}    \n",
    "evaluate(e_predictions,correct)\n",
    "evaluate(a_predictions,correct)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create dataset only from borderline cases. e.g. when one is correct and other one is not"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "labels,X,Y = [], [], [] \n",
    "\n",
    "for e_p, a_p in zip(er.values(), gr.values()):\n",
    "    assert e_p['raw_question'] == a_p['raw_question']\n",
    "    \n",
    "    \n",
    "    correct_answers = correct[e_p['raw_question']]\n",
    "    \n",
    "    \n",
    "    ep_best_score_idx  = argmax(e_p['reader_scores'])\n",
    "    ep_best_score = e_p['reader_scores'][ep_best_score_idx]\n",
    "    ep_prediction = e_p['answers'][ep_best_score_idx]\n",
    "    ep_correct= bool(eval_utils.metric_max_over_ground_truths(\n",
    "        metric_fn=exact_match_score, prediction=ep_prediction, ground_truths=correct_answers))\n",
    "    \n",
    "    ap_best_score_idx  = argmax(a_p['reader_scores'])\n",
    "    ap_best_score = a_p['reader_scores'][ap_best_score_idx]\n",
    "    ap_prediction = a_p['answers'][ap_best_score_idx]\n",
    "    ap_correct= bool(eval_utils.metric_max_over_ground_truths(\n",
    "        metric_fn=exact_match_score, prediction=ap_prediction, ground_truths=correct_answers))\n",
    "    \n",
    "    if ep_correct and not ap_correct:\n",
    "        labels.append(1)\n",
    "    elif not ep_correct and ap_correct:\n",
    "        labels.append(0)\n",
    "    else:\n",
    "        continue # skip non-borderline cases\n",
    "        \n",
    "    X.append(ep_best_score)\n",
    "    Y.append(ap_best_score)\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "labels_test,X_test,Y_test = [], [], [] \n",
    "BOTH_HIT = 2\n",
    "NONE_HIT= 3\n",
    "for e_p, a_p in zip(er.values(), gr.values()):\n",
    "    assert e_p['raw_question'] == a_p['raw_question']\n",
    "    \n",
    "    \n",
    "    correct_answers = correct[e_p['raw_question']]\n",
    "    \n",
    "    \n",
    "    ep_best_score_idx  = argmax(e_p['reader_scores'])\n",
    "    ep_best_score = e_p['reader_scores'][ep_best_score_idx]\n",
    "    ep_prediction = e_p['answers'][ep_best_score_idx]\n",
    "    ep_correct= bool(eval_utils.metric_max_over_ground_truths(\n",
    "        metric_fn=exact_match_score, prediction=ep_prediction, ground_truths=correct_answers))\n",
    "    \n",
    "    ap_best_score_idx  = argmax(a_p['reader_scores'])\n",
    "    ap_best_score = a_p['reader_scores'][ap_best_score_idx]\n",
    "    ap_prediction = a_p['answers'][ap_best_score_idx]\n",
    "    ap_correct= bool(eval_utils.metric_max_over_ground_truths(\n",
    "        metric_fn=exact_match_score, prediction=ap_prediction, ground_truths=correct_answers))\n",
    "    \n",
    "    if ep_correct and not ap_correct:\n",
    "        labels_test.append(1)\n",
    "    elif not ep_correct and ap_correct:\n",
    "        labels_test.append(0)\n",
    "           \n",
    "    elif ep_correct and ap_correct:\n",
    "        labels_test.append(BOTH_HIT)\n",
    "    elif not ep_correct and not ap_correct:\n",
    "        labels_test.append(NONE_HIT)\n",
    "        \n",
    "    X_test.append(ep_best_score)\n",
    "    Y_test.append(ap_best_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "class ConstrainedLR(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.a = torch.nn.Parameter(torch.randn((1), requires_grad=True))\n",
    "        self.b = torch.nn.Parameter(torch.randn((1), requires_grad=True))\n",
    "        self.bias = torch.nn.Parameter(torch.randn((1), requires_grad=True))\n",
    "        \n",
    "    def forward(self,X,Y):\n",
    "        r = self.a*X + self.b*Y + self.bias\n",
    "        return r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([ 2.5139, -0.6049,  0.8458, -1.5533,  1.3244,  0.6597,  1.3970,  0.7529,\n",
       "          0.3308,  0.1160]),\n",
       " tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1.]),\n",
       " tensor([1., 1., 1., 0., 1., 1., 1., 0., 0., 0.]))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "labels = torch.FloatTensor(labels)\n",
    "X = torch.FloatTensor(X)\n",
    "Y = torch.FloatTensor(Y)\n",
    "X_test = torch.FloatTensor(X_test)\n",
    "Y_test = torch.FloatTensor(Y_test)\n",
    "X[:10], Y[:10], labels[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "213"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.7081)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch.nn.functional as F\n",
    "F.binary_cross_entropy_with_logits(X+Y, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(preds, labels):\n",
    "    assert len(preds) == len(labels)\n",
    "    hits=0\n",
    "    total=len(labels)\n",
    "    for p,l in zip(preds.tolist(),labels):\n",
    "        if l==BOTH_HIT:\n",
    "            hits+=1\n",
    "        elif l==NONE_HIT:\n",
    "            pass\n",
    "        else:\n",
    "            hits+=int(p==l)\n",
    "    return hits/total*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "48.333333333333336: 100%|██████████| 1000/1000 [00:00<00:00, 1808.95it/s]\n",
      "48.333333333333336:  19%|█▉        | 189/1000 [00:00<00:00, 1883.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'a': 0.45572715997695923, 'b': 1.580994725227356, 'bias': -1.2058194875717163}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "48.333333333333336: 100%|██████████| 1000/1000 [00:00<00:00, 1923.69it/s]\n",
      "48.27777777777777: 100%|██████████| 1000/1000 [00:00<00:00, 1811.11it/s]\n",
      "48.27777777777777: 100%|██████████| 1000/1000 [00:00<00:00, 1788.67it/s]\n",
      "48.27777777777777: 100%|██████████| 1000/1000 [00:00<00:00, 1876.19it/s]\n",
      "48.27777777777777: 100%|██████████| 1000/1000 [00:00<00:00, 1849.75it/s]\n",
      "48.27777777777777: 100%|██████████| 1000/1000 [00:00<00:00, 1734.32it/s]\n",
      "48.333333333333336: 100%|██████████| 1000/1000 [00:00<00:00, 1836.75it/s]\n",
      "48.27777777777777: 100%|██████████| 1000/1000 [00:00<00:00, 1738.13it/s]\n",
      "48.27777777777777: 100%|██████████| 1000/1000 [00:00<00:00, 1736.42it/s]\n",
      "48.333333333333336: 100%|██████████| 1000/1000 [00:00<00:00, 1637.17it/s]\n",
      "48.27777777777777: 100%|██████████| 1000/1000 [00:00<00:00, 1826.48it/s]\n",
      "48.27777777777777: 100%|██████████| 1000/1000 [00:00<00:00, 1747.47it/s]\n",
      "48.333333333333336: 100%|██████████| 1000/1000 [00:00<00:00, 1504.51it/s]\n",
      "48.27777777777777: 100%|██████████| 1000/1000 [00:00<00:00, 1812.06it/s]\n",
      "48.27777777777777: 100%|██████████| 1000/1000 [00:00<00:00, 1836.44it/s]\n",
      "48.333333333333336: 100%|██████████| 1000/1000 [00:00<00:00, 1731.43it/s]\n",
      "48.333333333333336: 100%|██████████| 1000/1000 [00:00<00:00, 1698.99it/s]\n",
      "48.27777777777777: 100%|██████████| 1000/1000 [00:00<00:00, 1794.89it/s]\n",
      "48.27777777777777: 100%|██████████| 1000/1000 [00:00<00:00, 1704.47it/s]\n",
      "48.333333333333336: 100%|██████████| 1000/1000 [00:00<00:00, 1845.35it/s]\n",
      "48.27777777777777: 100%|██████████| 1000/1000 [00:00<00:00, 1859.04it/s]\n",
      "48.27777777777777: 100%|██████████| 1000/1000 [00:00<00:00, 1855.78it/s]\n",
      "48.333333333333336: 100%|██████████| 1000/1000 [00:00<00:00, 1747.50it/s]\n",
      "48.333333333333336: 100%|██████████| 1000/1000 [00:00<00:00, 1820.73it/s]\n",
      "48.333333333333336: 100%|██████████| 1000/1000 [00:00<00:00, 1901.61it/s]\n",
      "48.333333333333336: 100%|██████████| 1000/1000 [00:00<00:00, 1849.91it/s]\n",
      "48.27777777777777: 100%|██████████| 1000/1000 [00:00<00:00, 1765.51it/s]\n",
      "48.333333333333336: 100%|██████████| 1000/1000 [00:00<00:00, 1756.23it/s]\n",
      "48.333333333333336: 100%|██████████| 1000/1000 [00:00<00:00, 1750.01it/s]\n",
      "48.27777777777777: 100%|██████████| 1000/1000 [00:00<00:00, 1785.47it/s]\n",
      "48.27777777777777: 100%|██████████| 1000/1000 [00:00<00:00, 1733.15it/s]\n",
      "48.333333333333336: 100%|██████████| 1000/1000 [00:00<00:00, 1825.18it/s]\n",
      "48.333333333333336: 100%|██████████| 1000/1000 [00:00<00:00, 1845.52it/s]\n",
      "48.27777777777777: 100%|██████████| 1000/1000 [00:00<00:00, 1776.41it/s]\n",
      "48.333333333333336: 100%|██████████| 1000/1000 [00:00<00:00, 1786.07it/s]\n",
      "48.27777777777777: 100%|██████████| 1000/1000 [00:00<00:00, 1780.01it/s]\n",
      "48.333333333333336: 100%|██████████| 1000/1000 [00:00<00:00, 1837.42it/s]\n",
      "48.333333333333336: 100%|██████████| 1000/1000 [00:00<00:00, 1783.55it/s]\n",
      "48.27777777777777: 100%|██████████| 1000/1000 [00:00<00:00, 1569.90it/s]\n",
      "48.333333333333336: 100%|██████████| 1000/1000 [00:00<00:00, 1517.79it/s]\n",
      "48.27777777777777: 100%|██████████| 1000/1000 [00:00<00:00, 1714.02it/s]\n",
      "48.333333333333336: 100%|██████████| 1000/1000 [00:00<00:00, 1809.72it/s]\n",
      "48.27777777777777: 100%|██████████| 1000/1000 [00:00<00:00, 1829.65it/s]\n",
      "48.333333333333336: 100%|██████████| 1000/1000 [00:00<00:00, 1803.26it/s]\n",
      "48.333333333333336: 100%|██████████| 1000/1000 [00:00<00:00, 1797.66it/s]\n",
      "48.333333333333336: 100%|██████████| 1000/1000 [00:00<00:00, 1943.90it/s]\n",
      "48.333333333333336: 100%|██████████| 1000/1000 [00:00<00:00, 1879.39it/s]\n",
      "48.27777777777777: 100%|██████████| 1000/1000 [00:00<00:00, 1798.64it/s]\n",
      "48.27777777777777: 100%|██████████| 1000/1000 [00:00<00:00, 1731.33it/s]\n"
     ]
    }
   ],
   "source": [
    "import torch.nn.functional as F\n",
    "from tqdm import tqdm\n",
    "from transformers import get_linear_schedule_with_warmup\n",
    "\n",
    "def run_training():\n",
    "    STEPS=1000\n",
    "    model =  ConstrainedLR()\n",
    "    model = model.train()\n",
    "    opt = torch.optim.SGD(model.parameters(), lr=0.1)\n",
    "    scheduler = get_linear_schedule_with_warmup(\n",
    "                    opt,\n",
    "                    num_warmup_steps=10,\n",
    "                    num_training_steps=STEPS\n",
    "                )\n",
    "\n",
    "    best_acc= 0\n",
    "    best_r = None\n",
    "    iterator = tqdm(range(STEPS))\n",
    "\n",
    "    for i in iterator:\n",
    "        logits = model(X, Y)\n",
    "        l_list = F.binary_cross_entropy_with_logits(logits, labels, reduction='none')\n",
    "        l = l_list.mean()\n",
    "        l.backward()\n",
    "        opt.step()\n",
    "        scheduler.step()\n",
    "        opt.zero_grad()\n",
    "        if i % 1 == 0:\n",
    "            r = { k: v.item() for k,v in dict(model.named_parameters()).items()}\n",
    "            model.eval()\n",
    "            acc = evaluate_model((model(X_test,Y_test)>0).int(),labels_test)\n",
    "            model.train()\n",
    "            if acc>best_acc:\n",
    "                iterator.set_description(str(acc))\n",
    "                best_acc = acc\n",
    "                best_r = r\n",
    "    return best_acc, best_r\n",
    "\n",
    "total_best_acc, total_best_r = 0.,None\n",
    "for _ in range(50):\n",
    "    acc,r = run_training()\n",
    "    if acc>total_best_acc:\n",
    "        total_best_acc=acc\n",
    "        total_best_r=r\n",
    "        print(r)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "e.g.:\n",
    "```\n",
    "47.77777777777778 {'a': 0.5522062182426453, 'b': -0.7874355912208557, 'bias': 2.0110630989074707}\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "48.333333333333336 {'a': 0.45572715997695923, 'b': 1.580994725227356, 'bias': -1.2058194875717163}\n"
     ]
    }
   ],
   "source": [
    "print(total_best_acc, total_best_r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "48.333333333333336"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model =  ConstrainedLR()\n",
    "best = total_best_r\n",
    "best_sd = {k:torch.FloatTensor([v]) for k,v in best.items()}\n",
    "model.load_state_dict(best_sd)\n",
    "evaluate_model((model(X_test,Y_test)>0).int(),labels_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
